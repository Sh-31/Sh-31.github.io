<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Sherif Ahmed</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Sherif Ahmed</description>
    <generator>Hugo -- 0.151.0</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Sep 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Why Warmup the Learning Rate?</title>
      <link>http://localhost:1313/blogs/why-warmup-the-learning-rate/</link>
      <pubDate>Mon, 30 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blogs/why-warmup-the-learning-rate/</guid>
      <description>In this blog, I will try break down the findings from the paper “Why Warmup the Learning Rate? Underlying Mechanisms and Improvements” and explain how warm-up helps stabilize training by reducing gradient sharpness and enabling the use of higher learning rates.</description>
    </item>
    <item>
      <title>CourseTA</title>
      <link>http://localhost:1313/projects/courseta/</link>
      <pubDate>Tue, 03 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/courseta/</guid>
      <description>An agent-based educational system using FastAPI, LangChain, and LangGraph in a microservice architecture. Implemented real-time async endpoints, integrated Whisper for audio/video transcription, and PyMuPDF for PDF parsing. Built a RAG-based QA pipeline with embedding-based retrieval, and AI agents for question generation, summarization, and feedback refinement. Optimized for scalable human-in-the-loop workflows and efficient content transformation across diverse formats.</description>
    </item>
    <item>
      <title>DETR End-to-End Object Detection with Transformers</title>
      <link>http://localhost:1313/blogs/detection-transformer/</link>
      <pubDate>Fri, 26 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blogs/detection-transformer/</guid>
      <description>The Detection Transformer (DETR) represents a novel, end-to-end approach to object detection, reframing the task as a set prediction problem. This architecture relies on a transformer encoder-decoder structure and a unique assignment strategy involving the Hungarian matching algorithm, enabling the model to bypass post-processing steps like Non-Maximal Suppression (NMS) and reliance on anchor design.</description>
    </item>
    <item>
      <title>Group Activity Recognition</title>
      <link>http://localhost:1313/projects/group-activity-recognition/</link>
      <pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/group-activity-recognition/</guid>
      <description>A modern implementation implemented a Hierarchical Deep Temporal Model for Group Activity Recognition, based on the CVPR 2016 paper. Achieved 93% accuracy using a two-stage LSTM architecture to recognize multi-person activities. Conducted ablation studies to evaluate the contributions of various model components and compared performance against 8 baseline models.</description>
    </item>
    <item>
      <title>Relational Group Activity Recognition</title>
      <link>http://localhost:1313/projects/rgar/</link>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/rgar/</guid>
      <description>Implemented a Hierarchical Relational Network architecture for Group Activity Recognition and Retrieval, based on the ECCV 2018 paper. This implementation models inter-person relations and hierarchical temporal dynamics using Relational Layer (Graph Relational Layer). Ablation experiments were conducted to assess the impact of relation modeling, attention mechanisms (Graph Attention Operator), and hierarchical layers.</description>
    </item>
    <item>
      <title>ImgCap</title>
      <link>http://localhost:1313/projects/imacap/</link>
      <pubDate>Tue, 10 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/imacap/</guid>
      <description>ImgCap is an image captioning model designed to automatically generate descriptive captions for images. It has two versions one based on a CNN-LSTM architecture, and the other an enhanced version that integrates a CNN-LSTM with an Attention mechanism. To further enhance the quality and coherence of generated captions, beam search is implemented during the inference stage.</description>
    </item>
    <item>
      <title>Credit Card Fraud Detection</title>
      <link>http://localhost:1313/projects/credit-card-fraud-detection/</link>
      <pubDate>Mon, 02 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/credit-card-fraud-detection/</guid>
      <description>Credit card fraud detection project using a highly unbalanced Kaggle dataset of 284,807 transactions with only 492 frauds. To address the imbalance the project implements a voting classifier and a neural network with focal loss in PyTorch achieving an F1 score of 86% and a PR AUC of 85%</description>
    </item>
    <item>
      <title>Tennis Analysis System</title>
      <link>http://localhost:1313/projects/tennis-analysis-system/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/tennis-analysis-system/</guid>
      <description>Tennis-Analysis-System is a system that analyzes tennis matches and provides player statistics and mini court visualizations.</description>
    </item>
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;m Sherif Ahmed, a Machine Learning Engineer with expertise in Computer Vision, Natural Language Processing, and Large
Language Models (LLMs). Delivered production-ready AI and ML solutions through internships at CyberTalents
and various freelance projects I have worked on, with a focus on implementing and optimizing systems for
efficiency and scalability. Skilled in Python, PyTorch, LangGraph, LangChain, SQL, and Docker with a strong track
record in conducting research and driving cross-functional collaboration to deliver impactful AI solutions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Engineer Intern</title>
      <link>http://localhost:1313/experience/cybertalents/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/experience/cybertalents/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Led a small team of interns in collaboration with the Research and Technical Writing departments to develop utilities LLMs for CTF Write-ups generation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Designed and implemented data cleaning pipelines and developed workflows for generating synthetic datasets.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Conducted instruction fine-tuning of LLMs using LitGPT, optimizing models for domain-specific tasks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Worked on system integration and internal service automation to improve team workflows and productivity.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
